一、Execsouce的缺点
		execsource和异步的source一样，无法在source向channel中放入event故障时，及时通知客户端，暂停生成数据！
		容易造成数据丢失！
		
		解决方案： 需要在发生故障时，及时通知客户端！
					如果客户端无法暂停，必须有一个数据的缓存机制！
					
		如果希望数据有强的可靠性保证，可以考虑使用SpoolingDirSource或TailDirSource或自己写Source自己控制！
		
二、常用的source
1.SpoolingDirSource
	简介：
		SpoolingDirSource指定本地磁盘的一个目录为"Spooling(自动收集)"的目录！这个source可以读取目录中
		新增的文件，将文件的内容封装为event!
		
		SpoolingDirSource在读取一整个文件到channel之后，它会采取策略，要么删除文件(是否可以删除取决于配置)，要么对文件
		进程一个完成状态的重命名，这样可以保证source持续监控新的文件！
		
		SpoolingDirSource和execsource不同，SpoolingDirSource是可靠的！即使flume被杀死或重启，依然不丢数据！但是为了保证
		这个特性，付出的代价是，一旦flume发现以下情况，flume就会报错，停止！
				①一个文件已经被放入目录，在采集文件时，不能被修改
				②文件的名在放入目录后又被重新使用（出现了重名的文件）
				
		要求： 必须已经封闭的文件才能放入到SpoolingDirSource，在同一个SpoolingDirSource中都不能出现重名的文件！
	使用：
		必需配置：
		type	–	The component type name, needs to be spooldir.
		spoolDir	–	The directory from which to read files from.
		
案例三：
#a1是agent的名称，a1中定义了一个叫r1的source，如果有多个，使用空格间隔
a1.sources = r1
a1.sinks = k1
a1.channels = c1
#组名名.属性名=属性值
a1.sources.r1.type=spooldir
a1.sources.r1.spoolDir=/home/atguigu/flume

#定义chanel
a1.channels.c1.type=memory
a1.channels.c1.capacity=1000

#定义sink
a1.sinks.k1.type = hdfs
#一旦路径中含有基于时间的转义序列，要求event的header中必须有timestamp=时间戳，如果没有需要将useLocalTimeStamp = true
a1.sinks.k1.hdfs.path = hdfs://hadoop101:9000/flume/%Y%m%d/%H/%M
#上传文件的前缀
a1.sinks.k1.hdfs.filePrefix = logs-

#以下三个和目录的滚动相关，目录一旦设置了时间转义序列，基于时间戳滚动
#是否将时间戳向下舍
a1.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
a1.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
a1.sinks.k1.hdfs.roundUnit = minute

#是否使用本地时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a1.sinks.k1.hdfs.batchSize = 100

#以下三个和文件的滚动相关，以下三个参数是或的关系！以下三个参数如果值为0都代表禁用！
#60秒滚动生成一个新的文件
a1.sinks.k1.hdfs.rollInterval = 30
#设置每个文件到128M时滚动
a1.sinks.k1.hdfs.rollSize = 134217700
#每写多少个event滚动一次
a1.sinks.k1.hdfs.rollCount = 0
#以不压缩的文本形式保存数据
a1.sinks.k1.hdfs.fileType=DataStream 


#连接组件 同一个source可以对接多个channel，一个sink只能从一个channel拿数据！
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1

2.TailDirSource
		flume ng 1.7版本后提供！
		
		常见问题： TailDirSource采集的文件，不能随意重命名！如果日志在正在写入时，名称为 xxxx.tmp，写入完成后，滚动，
					改名为xxx.log，此时一旦匹配规则可以匹配上述名称，就会发生数据的重复采集！
	简介：
		Taildir Source 可以读取多个文件最新追加写入的内容！
		Taildir Source是可靠的，即使flume出现了故障或挂掉。Taildir Source在工作时，会将读取文件的最后的位置记录在一个
		json文件中，一旦agent重启，会从之前已经记录的位置，继续执行tail操作！
		
		Json文件中，位置是可以修改，修改后，Taildir Source会从修改的位置进行tail操作！如果JSON文件丢失了，此时会重新从
		每个文件的第一行，重新读取，这会造成数据的重复！
		
		Taildir Source目前只能读文本文件！
		
	必需配置：
		channels	–	 
		type	–	The component type name, needs to be TAILDIR.
		filegroups	–	Space-separated list of file groups. Each file group indicates a set of files to be tailed.
		filegroups.<filegroupName>	–	Absolute path of the file group. Regular expression (and not file system patterns) can be used for filename only.


案例四： 使用TailDirSource和logger sink
#a1是agent的名称，a1中定义了一个叫r1的source，如果有多个，使用空格间隔
a1.sources = r1
a1.sinks = k1
a1.channels = c1
#组名名.属性名=属性值
a1.sources.r1.type=TAILDIR
a1.sources.r1.filegroups=f1 f2
a1.sources.r1.filegroups.f1=/home/atguigu/hi
a1.sources.r1.filegroups.f2=/home/atguigu/test

#定义sink
a1.sinks.k1.type=logger
a1.sinks.k1.maxBytesToLog=100

#定义chanel
a1.channels.c1.type=memory
a1.channels.c1.capacity=1000

#连接组件 同一个source可以对接多个channel，一个sink只能从一个channel拿数据！
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1


